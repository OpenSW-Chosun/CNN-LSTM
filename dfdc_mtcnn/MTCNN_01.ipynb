{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMLLcb5eR8AUCRNv9BCjXdj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6cPzYj_0ElJs","executionInfo":{"status":"ok","timestamp":1730875715639,"user_tz":-540,"elapsed":2334,"user":{"displayName":"Heeju Seo","userId":"02785407679794380503"}},"outputId":"0e5357cf-21da-46df-ce8a-8452e2c38c50"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["# 5개 영상만 사용해 MTCNN 모델 활용 - 얼굴 추출 및 시각화"],"metadata":{"id":"v6gif0cEE9SB"}},{"cell_type":"code","source":["!pip install facenet_pytorch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"id":"WyDdmD9VNuIZ","executionInfo":{"status":"ok","timestamp":1730875645232,"user_tz":-540,"elapsed":202916,"user":{"displayName":"Heeju Seo","userId":"02785407679794380503"}},"outputId":"b3935004-b408-4be6-c97d-4105ef53a299"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting facenet_pytorch\n","  Downloading facenet_pytorch-2.6.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: numpy<2.0.0,>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from facenet_pytorch) (1.26.4)\n","Collecting Pillow<10.3.0,>=10.2.0 (from facenet_pytorch)\n","  Downloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n","Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from facenet_pytorch) (2.32.3)\n","Collecting torch<2.3.0,>=2.2.0 (from facenet_pytorch)\n","  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n","Collecting torchvision<0.18.0,>=0.17.0 (from facenet_pytorch)\n","  Downloading torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from facenet_pytorch) (4.66.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->facenet_pytorch) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->facenet_pytorch) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->facenet_pytorch) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->facenet_pytorch) (2024.8.30)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet_pytorch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet_pytorch)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet_pytorch)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.3.0,>=2.2.0->facenet_pytorch)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.3.0,>=2.2.0->facenet_pytorch)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.3.0,>=2.2.0->facenet_pytorch)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch<2.3.0,>=2.2.0->facenet_pytorch)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.3.0,>=2.2.0->facenet_pytorch)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.3.0,>=2.2.0->facenet_pytorch)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch<2.3.0,>=2.2.0->facenet_pytorch)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet_pytorch)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.2.0 (from torch<2.3.0,>=2.2.0->facenet_pytorch)\n","  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3.0,>=2.2.0->facenet_pytorch) (12.6.77)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet_pytorch) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.3.0,>=2.2.0->facenet_pytorch) (1.3.0)\n","Downloading facenet_pytorch-2.6.0-py3-none-any.whl (1.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: triton, Pillow, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, facenet_pytorch\n","  Attempting uninstall: Pillow\n","    Found existing installation: pillow 10.4.0\n","    Uninstalling pillow-10.4.0:\n","      Successfully uninstalled pillow-10.4.0\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.23.4\n","    Uninstalling nvidia-nccl-cu12-2.23.4:\n","      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n","    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.7.77\n","    Uninstalling nvidia-curand-cu12-10.3.7.77:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n","    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n","      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n","    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n","    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n","    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n","      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n","    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n","    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.0+cu121\n","    Uninstalling torch-2.5.0+cu121:\n","      Successfully uninstalled torch-2.5.0+cu121\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.20.0+cu121\n","    Uninstalling torchvision-0.20.0+cu121:\n","      Successfully uninstalled torchvision-0.20.0+cu121\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.5.0+cu121 requires torch==2.5.0, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed Pillow-10.2.0 facenet_pytorch-2.6.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.2 torchvision-0.17.2 triton-2.2.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL"]},"id":"ccfe7b4c57084a3dbceaccc5080d3364"}},"metadata":{}}]},{"cell_type":"code","source":["from facenet_pytorch import MTCNN\n","import torch\n","import cv2\n","import matplotlib.pyplot as plt\n","import os"],"metadata":{"id":"dwXT9YQIFWez","executionInfo":{"status":"ok","timestamp":1730877322965,"user_tz":-540,"elapsed":319,"user":{"displayName":"Heeju Seo","userId":"02785407679794380503"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# MTCNN 모델 초기화\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","mtcnn = MTCNN(keep_all=True, device=device)\n","\n","\n","# 장치 정보 출력\n","print(f\"Using device: {device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fwsVhu2HFibV","executionInfo":{"status":"ok","timestamp":1730878602268,"user_tz":-540,"elapsed":384,"user":{"displayName":"Heeju Seo","userId":"02785407679794380503"}},"outputId":"71436783-8648-42f8-9170-02e732f6c0da"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}]},{"cell_type":"code","source":["# 3. 5개의 영상 파일 경로 설정\n","video_paths = [\n","    '/content/drive/MyDrive/OSSW/dfdc_mtcnn/mini_data/train_minidata/mini_aagfhgtpmv.mp4',\n","    '/content/drive/MyDrive/OSSW/dfdc_mtcnn/mini_data/train_minidata/mini_aapnvogymq.mp4',\n","    '/content/drive/MyDrive/OSSW/dfdc_mtcnn/mini_data/train_minidata/mini_abarnvbtwb.mp4',\n","    '/content/drive/MyDrive/OSSW/dfdc_mtcnn/mini_data/train_minidata/mini_abofeumbvv.mp4',\n","    '/content/drive/MyDrive/OSSW/dfdc_mtcnn/mini_data/train_minidata/mini_abqwwspghj.mp4'\n","]\n","\n","# 각 비디오 파일 경로 존재 여부 확인\n","for video_path in video_paths:\n","    if os.path.exists(video_path):\n","        print(f\"{video_path} 존재\")\n","    else:\n","        print(f\"{video_path} 존재 안함. 경로 다시 체크 필요\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wa3pdxLwFieP","executionInfo":{"status":"ok","timestamp":1730878798514,"user_tz":-540,"elapsed":332,"user":{"displayName":"Heeju Seo","userId":"02785407679794380503"}},"outputId":"d95899e6-9eec-4c5d-a2c5-f42719965a53"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/OSSW/dfdc_mtcnn/mini_data/train_minidata/mini_aagfhgtpmv.mp4 존재\n","/content/drive/MyDrive/OSSW/dfdc_mtcnn/mini_data/train_minidata/mini_aapnvogymq.mp4 존재\n","/content/drive/MyDrive/OSSW/dfdc_mtcnn/mini_data/train_minidata/mini_abarnvbtwb.mp4 존재\n","/content/drive/MyDrive/OSSW/dfdc_mtcnn/mini_data/train_minidata/mini_abofeumbvv.mp4 존재\n","/content/drive/MyDrive/OSSW/dfdc_mtcnn/mini_data/train_minidata/mini_abqwwspghj.mp4 존재\n"]}]},{"cell_type":"markdown","source":["1. video_paths : 비디오 리스트\n","2. cap : openCV 함수 비디오 파일 읽는 개체\n","3. frame_rate : 비디오 초당 프레임 수\n","(재생속도)\n","4. total_frames : 비디오의 전체 프레임 수 반환\n","5. frame_interval : 프레임 추출하는 간격 - 10 프레임\n","6. max_frames : 얼굴 검출 최대 프레임 수 (최대 32까지)\n","7. detected_face : 검출된 얼굴 저장 - 리스트\n","8. frame_count : 현재 읽은 프레임 수 추척 (10프레임마다 한번씩)\n","9. extracted_frame_count : 실제 얼굴 검출 수행한 프레임 (max_frames넘으면 중단)\n","10 ret : 프레임을 정상적으로 읽었는지 값(false - 중단)\n","11. frame : 실제 비디오 프레임 이미지 - 얼굴검출에 사용\n","12. frb_frame : rgb형식으로 변환한 값\n","13. faces : 얼굴 검출 함수"],"metadata":{"id":"Xatdjh3paxlc"}},{"cell_type":"markdown","source":["## 파일 및 경로 테스트"],"metadata":{"id":"GgVlWGtCdqu4"}},{"cell_type":"code","source":["# 첫 번째 비디오 파일만 테스트로 열어 확인\n","\n","video_path = video_paths[0]\n","cap = cv2.VideoCapture(video_path)\n","\n","if cap.isOpened():\n","    frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n","    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    print(f\"Video '{video_path}' opened successfully.\")\n","    print(f\"Frame rate: {frame_rate}, Total frames: {total_frames}\")\n","else:\n","    print(f\"Failed to open video '{video_path}'.\")\n","cap.release()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bvp0Q5D2bPzz","executionInfo":{"status":"ok","timestamp":1730878979833,"user_tz":-540,"elapsed":352,"user":{"displayName":"Heeju Seo","userId":"02785407679794380503"}},"outputId":"0d116857-7166-48fc-aaa8-78bcbfc606b8"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Video '/content/drive/MyDrive/OSSW/dfdc_mtcnn/mini_data/train_minidata/mini_aagfhgtpmv.mp4' opened successfully.\n","Frame rate: 29, Total frames: 300\n"]}]},{"cell_type":"code","source":["# 프레임을 하나 추출, rgb로 변환 후 변환된 프레임 크기 확인하기\n","\n","cap = cv2.VideoCapture(video_path)\n","ret, frame = cap.read()\n","if ret:\n","    # 프레임을 RGB로 변환\n","    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","    print(f\"Extracted frame shape: {rgb_frame.shape}\")  # 예상 결과: (height, width, 3)\n","else:\n","    print(\"Failed to read the frame.\")\n","cap.release()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vmfiKTf-bc5d","executionInfo":{"status":"ok","timestamp":1730879056104,"user_tz":-540,"elapsed":3,"user":{"displayName":"Heeju Seo","userId":"02785407679794380503"}},"outputId":"407007b8-1e5d-4108-9310-e0c2371f41c9"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracted frame shape: (1080, 1920, 3)\n"]}]},{"cell_type":"code","source":["# 얼굴 검출 수행 / 확인\n","# 몇개의 얼굴이 검출되었나?\n","\n","faces = mtcnn(rgb_frame)\n","if faces is not None:\n","    print(f\"Faces detected: {len(faces)}\")\n","else:\n","    print(\"No faces detected.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jj4zHLIWbpOC","executionInfo":{"status":"ok","timestamp":1730879096463,"user_tz":-540,"elapsed":2227,"user":{"displayName":"Heeju Seo","userId":"02785407679794380503"}},"outputId":"01d0c2c8-30d6-49ed-cc6f-de2f1066f1e1"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Faces detected: 1\n"]}]},{"cell_type":"code","source":["if faces is not None and len(faces) > 0:\n","    plt.figure(figsize=(10, 5))\n","    for i, face in enumerate(faces[:5]):  # 최대 5개만 시각화\n","        plt.subplot(1, len(faces[:5]), i + 1)\n","        plt.imshow(face.permute(1, 2, 0).int())\n","        plt.axis('off')\n","    plt.show()\n","\n","    # 저장 경로 설정 및 확인\n","    save_path = '/content/drive/MyDrive/OSSW/dfdc_mtenn/mini_data/saved_face/'\n","    os.makedirs(save_path, exist_ok=True)\n","    print(f\"Save path exists: {os.path.exists(save_path)}\")\n","else:\n","    print(\"No faces detected to display.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":440},"id":"t_ag1Dp_b-Ya","executionInfo":{"status":"ok","timestamp":1730879355267,"user_tz":-540,"elapsed":324,"user":{"displayName":"Heeju Seo","userId":"02785407679794380503"}},"outputId":"36f051c3-95f3-41b5-a3b7-c09e8c4f0d10"},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x500 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Save path exists: True\n"]}]},{"cell_type":"code","source":["# 아직하지마\n","# 4. 각 영상에서 얼굴 검출 및 시각화\n","\n","\n","for i, video_path in enumerate(video_paths):\n","    cap = cv2.VideoCapture(video_path)\n","    frame_rate = int(cap.get(cv2.CAP_PROP_FPS))  # 영상의 초당 프레임 수\n","    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # 전체 프레임 수\n","\n","    frame_interval = 5  # 5개 프레임마다 한 프레임 추출\n","    max_frames = min(32, total_frames // frame_interval)  # 최대 32개 프레임 추출\n","\n","    detected_faces = []\n","    frame_count = 0\n","    extracted_frame_count = 0\n","\n","    while cap.isOpened() and extracted_frame_count < max_frames:\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        # 10개 프레임마다 1개 프레임 추출\n","        if frame_count % frame_interval == 0:\n","            print(f\"Processing frame {frame_count}...\")  # 현재 처리 중인 프레임 출력\n","\n","            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # 프레임을 RGB로 변환\n","\n","            # RGB 변환 후 shape 확인\n","            print(f\"RGB frame shape: {rgb_frame.shape}\")  # (height, width, channels) 확인\n","\n","            faces = mtcnn(rgb_frame)  # 얼굴 검출\n","            extracted_frame_count += 1\n","\n","            if faces is not None:\n","                print(f\"Faces detected in frame {frame_count}: {len(faces)} faces\")  # 얼굴 개수 출력\n","                for face in faces:\n","                    detected_faces.append(face)\n","                else:\n","                    print(f\"No faces detected in frame {frame_count}\")  # 얼굴 검출 안됨\n","\n","        frame_count += 1\n","\n","    cap.release()  # 비디오 캡처 객체 닫기\n","\n","    # 시각화\n","    if detected_faces:\n","        plt.figure(figsize=(20, 5))\n","        for j, face in enumerate(detected_faces[:5]):  # 최대 5개의 얼굴만 시각화\n","            plt.subplot(1, len(detected_faces[:5]), j + 1)\n","            plt.imshow(face.permute(1, 2, 0).int())\n","            plt.axis('off')\n","            plt.suptitle(f'Faces detected from video_{i + 1}.mp4')\n","\n","            # 저장할 폴더 경로\n","            save_path = f'/content/drive/MyDrive/OSSW/dfdc_mtcnn/mini_data/saved_face/'\n","            # 이미지 파일로 저장\n","            save_filename = f'{save_path}face_{j + 1}.png'\n","            plt.savefig(save_filename, bbox_inches='tight')\n","            plt.close()  # 그래프 닫기\n","    else:\n","        print(f\"No faces detected in video_{i + 1}.mp4\")"],"metadata":{"id":"ZfkvW1LcFigt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5개영상 얼굴 검출, 이미지 파일 저장"],"metadata":{"id":"SC2l43mTeHqP"}},{"cell_type":"code","source":["# 비디오 파일 경로 리스트\n","video_paths = [\n","    '/content/drive/MyDrive/OSSW/dfdc_mtcnn/mini_data/train_minidata/mini_aagfhgtpmv.mp4',\n","    '/content/drive/MyDrive/OSSW/dfdc_mtcnn/mini_data/train_minidata/mini_aapnvogymq.mp4',\n","    '/content/drive/MyDrive/OSSW/dfdc_mtcnn/mini_data/train_minidata/mini_abarnvbtwb.mp4',\n","    '/content/drive/MyDrive/OSSW/dfdc_mtcnn/mini_data/train_minidata/mini_abofeumbvv.mp4',\n","    '/content/drive/MyDrive/OSSW/dfdc_mtcnn/mini_data/train_minidata/mini_abqwwspghj.mp4'\n","]\n","\n","# 얼굴 검출 및 저장 경로 설정\n","save_path = '/content/drive/MyDrive/OSSW/dfdc_mtcnn/mini_data/saved_face/'\n","os.makedirs(save_path, exist_ok=True)\n","\n","# 각 비디오에서 얼굴 검출 및 저장\n","for i, video_path in enumerate(video_paths):\n","    cap = cv2.VideoCapture(video_path)\n","    frame_interval = 10  # 10 프레임마다 얼굴 검출\n","    max_frames = 32      # 최대 32개 프레임에서 얼굴 검출\n","    detected_faces = []   # 검출된 얼굴을 저장할 리스트\n","    frame_count = 0\n","    extracted_frame_count = 0\n","\n","    while cap.isOpened() and extracted_frame_count < max_frames:\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        # 설정한 간격에 맞춰 프레임 추출\n","        if frame_count % frame_interval == 0:\n","            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","            faces = mtcnn(rgb_frame)  # 얼굴 검출 수행\n","            extracted_frame_count += 1\n","\n","            # 얼굴이 검출되었을 때 리스트에 추가\n","            if faces is not None and len(faces) > 0:\n","                detected_faces.extend(faces)\n","\n","        frame_count += 1\n","    cap.release()\n","\n","    # 검출된 얼굴이 있을 경우 최대 5개까지 저장\n","    if detected_faces:\n","        for j, face in enumerate(detected_faces[:5]):  # 최대 5개만 저장\n","            # 이미지 파일 경로 및 이름 설정\n","            save_filename = os.path.join(save_path, f'video_{i+1}_face_{j+1}.png')\n","            plt.imshow(face.permute(1, 2, 0).int())\n","            plt.axis('off')\n","            plt.savefig(save_filename, bbox_inches='tight')\n","            plt.close()\n","        print(f\"Faces from video_{i+1} saved successfully.\")\n","    else:\n","        print(f\"No faces detected in video_{i + 1}.mp4\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1LlRmMQyFilo","executionInfo":{"status":"ok","timestamp":1730879855787,"user_tz":-540,"elapsed":37158,"user":{"displayName":"Heeju Seo","userId":"02785407679794380503"}},"outputId":"e612149d-ab98-4585-a99b-ac35f62b27a4"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Faces from video_1 saved successfully.\n","Faces from video_2 saved successfully.\n","Faces from video_3 saved successfully.\n","Faces from video_4 saved successfully.\n","Faces from video_5 saved successfully.\n"]}]},{"cell_type":"code","source":["# 비디오 파일 경로 리스트\n","video_paths = [\n","    '/content/drive/MyDrive/OSSW/dfdc_mtcnn/mini_data/train_minidata/mini_aagfhgtpmv.mp4',\n","    '/content/drive/MyDrive/OSSW/dfdc_mtcnn/mini_data/train_minidata/mini_aapnvogymq.mp4',\n","    '/content/drive/MyDrive/OSSW/dfdc_mtcnn/mini_data/train_minidata/mini_abarnvbtwb.mp4',\n","    '/content/drive/MyDrive/OSSW/dfdc_mtcnn/mini_data/train_minidata/mini_abofeumbvv.mp4',\n","    '/content/drive/MyDrive/OSSW/dfdc_mtcnn/mini_data/train_minidata/mini_abqwwspghj.mp4'\n","]\n","\n","# 얼굴 검출 및 저장 경로 설정\n","save_path = '/content/drive/MyDrive/OSSW/dfdc_mtcnn/mini_data/saved_face/'\n","\n","# 저장 경로가 존재하는지 확인하고, 없으면 생성합니다.\n","os.makedirs(save_path, exist_ok=True)\n","\n","# 각 비디오에서 얼굴 검출 및 저장\n","for i, video_path in enumerate(video_paths):\n","    cap = cv2.VideoCapture(video_path)\n","    frame_interval = 10  # 10 프레임마다 얼굴 검출\n","    max_frames = 32      # 최대 32개 프레임에서 얼굴 검출\n","    detected_faces = []   # 검출된 얼굴을 저장할 리스트\n","    frame_count = 0\n","    extracted_frame_count = 0\n","\n","    while cap.isOpened() and extracted_frame_count < max_frames:\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        # 설정한 간격에 맞춰 프레임 추출\n","        if frame_count % frame_interval == 0:\n","            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","            faces = mtcnn(rgb_frame)  # 얼굴 검출 수행\n","            extracted_frame_count += 1\n","\n","            # 얼굴이 검출되었을 때 리스트에 추가\n","            if faces is not None and len(faces) > 0:\n","                detected_faces.extend(faces)\n","\n","        frame_count += 1\n","    cap.release()\n","\n","    # 검출된 얼굴이 있을 경우 최대 5개까지 저장\n","    if detected_faces:\n","        for j, face in enumerate(detected_faces[:5]):  # 최대 5개만 저장\n","            # face 텐서를 [0, 255] 범위의 uint8 형식으로 변환\n","            face_img = (face.permute(1, 2, 0).clamp(0, 1) * 255).byte().cpu().numpy()\n","\n","            # 이미지 파일 경로 및 이름 설정\n","            save_filename = os.path.join(save_path, f'video_{i+1}_face_{j+1}.png')\n","            # 저장 경로가 존재하는지 다시 한번 확인합니다.\n","            os.makedirs(os.path.dirname(save_filename), exist_ok=True)\n","            plt.imsave(save_filename, face_img)\n","            print(f\"Faces from video_{i+1} saved successfully.\")\n","    else:\n","        print(f\"No faces detected in video_{i + 1}.mp4\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R7dK5nQHFin-","executionInfo":{"status":"ok","timestamp":1730880661184,"user_tz":-540,"elapsed":32812,"user":{"displayName":"Heeju Seo","userId":"02785407679794380503"}},"outputId":"e4aea44d-01b7-4fd2-b26c-797cfba94c94"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Faces from video_1 saved successfully.\n","Faces from video_1 saved successfully.\n","Faces from video_1 saved successfully.\n","Faces from video_1 saved successfully.\n","Faces from video_1 saved successfully.\n","Faces from video_2 saved successfully.\n","Faces from video_2 saved successfully.\n","Faces from video_2 saved successfully.\n","Faces from video_2 saved successfully.\n","Faces from video_2 saved successfully.\n","Faces from video_3 saved successfully.\n","Faces from video_3 saved successfully.\n","Faces from video_3 saved successfully.\n","Faces from video_3 saved successfully.\n","Faces from video_3 saved successfully.\n","Faces from video_4 saved successfully.\n","Faces from video_4 saved successfully.\n","Faces from video_4 saved successfully.\n","Faces from video_4 saved successfully.\n","Faces from video_4 saved successfully.\n","Faces from video_5 saved successfully.\n","Faces from video_5 saved successfully.\n","Faces from video_5 saved successfully.\n","Faces from video_5 saved successfully.\n","Faces from video_5 saved successfully.\n"]}]}]}